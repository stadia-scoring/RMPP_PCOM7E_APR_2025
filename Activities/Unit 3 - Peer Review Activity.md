## Activity: 
In preparation for this week’s seminar, you will need to source at least 2 papers in a Computing subject of your choice (AI, Cybersecurity, Data Science, or a general interest topic in Computer Science), provided they utilise two different types of research methods to achieve their goal/research aims. Now answer the following questions (please provide justifications for your answers) and be prepared to discuss them in the session: 

- Familiarise yourself with the purpose, problem, objective or research question of each paper. Are they in line with your experience or thoughts on the topic, contributing to the collective body of knowledge in this area?
- Is the research methodology utilised in each paper appropriate for the stated purpose or question? 
- In terms of data collection and analysis, is this also appropriate for the stated purpose or question? (We will discuss this further in upcoming units.)
- Does each paper support its claims and conclusions with explicit arguments or evidence?
- How would you enhance the work/paper?
- You can set up your responses as a presentation for the group. Remember to record your answers and feedback in your e-Portfolio.

## Evaluating Literature for Research Design and Methodology

**Topic:** *Exploring LLMs and AI in Risk Management and Compliance Automation*

---

## Paper 1: “Bridging Expertise Gaps: The Role of LLMs in Human-AI Collaboration for Cybersecurity”  
**Citation:** Tariq, S., Singh, R., Chhetri, M. B., Nepal, S., & Paris, C. (2025). *Bridging Expertise Gaps: The Role of LLMs in Human-AI Collaboration for Cybersecurity*. arXiv preprint arXiv:2505.03179v1.

### 1. Purpose / Contribution
- Investigates how LLMs can support non-expert users in cybersecurity tasks (phishing and intrusion detection).
- Directly aligns with the research focus on automating and augmenting risk-sensitive processes like RMF.

### 2. Research Methodology
- **Mixed-methods user study** with 58 participants.
- Combines quantitative metrics (e.g., F1-score) with qualitative analysis of AI-human interaction.

### 3. Data Collection and Analysis
- Controlled experiments using GPT-4 and LLaMA-2 models.
- Interaction logs, survey feedback, and statistical performance metrics analyzed.

### 4. Support for Claims
- Robust empirical evidence with performance comparisons across control and AI-assisted scenarios.
- Strong thematic coding of interaction patterns supports qualitative findings.

### 5. Suggestions for Enhancement
- Expand study to include SOC environments or RMF-specific documentation tasks.
- Introduce longitudinal tracking for learning and skill development effects.

---

## Paper 2: “Augmenting the Watchdog: AI-Driven Compliance Audits for Enhanced Efficiency and Accuracy”  
**Citation:** Devineni, S. K. (2021). *Augmenting the Watchdog: AI-Driven Compliance Audits for Enhanced Efficiency and Accuracy*. *International Journal of Science and Research*, 10(12). DOI: [10.21275/SR24127205916](https://dx.doi.org/10.21275/SR24127205916)

### 1. Purpose / Contribution
- Explores how AI techniques like ML, NLP, and RPA can transform compliance audits.
- Broadens understanding of audit automation across public and private sectors.

### 2. Research Methodology
- **Conceptual framework synthesis** based on literature and domain-specific use cases.
- Well-suited for foundational exploration but lacks experimental validation.

### 3. Data Collection and Analysis
- Secondary data from literature and practical implementations.
- Provides descriptions of AI frameworks and technologies rather than empirical results.

### 4. Support for Claims
- Draws on case examples and cited research to support conceptual recommendations.
- Lacks direct performance metrics or controlled evaluations.

### 5. Suggestions for Enhancement
- Validate proposed frameworks through pilot testing or simulations.
- Focus specifically on RMF or NIST 800-53 assessment processes for higher relevance.

---

## Comparative Reflection

| **Aspect** | **Paper 1 (LLMs for Cybersecurity)** | **Paper 2 (AI for Compliance Audits)** |
|-----------|--------------------------------------|----------------------------------------|
| Methodology | Mixed-methods empirical | Conceptual synthesis |
| Data | Experimental + qualitative | Secondary literature and case studies |
| Contribution to My Topic | High – supports LLM use in analyst workflows | Moderate – sets AI context but not RMF-specific |
| Area for Improvement | Real-world DoD integration | Empirical testing of frameworks |

---

**Conclusion:**  
These papers demonstrate both the potential and complexity of integrating AI/LLMs into regulated environments like RMF. Paper 1 showcases performance gains and trust dynamics in human-AI teaming. Paper 2 establishes the foundational promise of AI in auditing but calls for focused validation. Together, they reinforce the importance of combining **technical accuracy** with **human trust** and **explainability** in cybersecurity automation.


