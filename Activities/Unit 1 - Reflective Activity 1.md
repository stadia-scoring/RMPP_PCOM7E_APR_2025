# Reflection on Global AI Ethics and Governance in the Age of Generative AI

The rise of generative artificial intelligence (AI) since late 2022 has transformed nearly every facet of human activity, from education and journalism to creative design and cybersecurity. Yet this technological breakthrough has outpaced the development of ethical, legal, and professional frameworks meant to govern it. While AI is not inherently new, the scale, autonomy, and unpredictability of generative models necessitate a shift from abstract principles to enforceable, globally relevant ethical standards. This reflection draws on foundational and contemporary literature to explore how divergent global approaches to AI ethics pose challenges to governance, and recommends a set of coordinated, inclusive, and actionable responses to ensure responsible AI use.

A key theme across the literature is the convergence of ethical principles amid a divergence in practice. Correa et al. (2023) conducted a sweeping review of 200 AI governance documents and found a broad consensus around five core values: transparency, justice, non-maleficence, responsibility, and privacy. Yet they also reveal that these values are unevenly implemented, with most frameworks lacking enforcement mechanisms. Notably, they highlight an imbalance in authorship: over 70% of guidelines come from North America and Europe, leaving the Global South underrepresented. This raises concerns of "ethical colonialism"—where norms developed in powerful nations are exported to regions with different social, legal, and cultural contexts.

This fragmentation is further illustrated in Jobin, Ienca and Vayena's (2019) analysis, which confirms that although shared values dominate discourse, inconsistencies emerge in how ethics are operationalised. For example, while both China and the European Union advocate AI safety, China emphasises state control and national security, whereas the EU foregrounds human dignity and autonomy. Without harmonisation, such divergence risks the creation of fragmented regulatory ecosystems that are ill-equipped to govern transnational technologies like generative AI.

Deckard (2023) reinforces the notion that ethics in AI must extend beyond regulatory compliance. He identifies three domains—design, deployment, and impact—that require ethical scrutiny. In the context of generative AI, this means not only building systems with fair and transparent algorithms, but also monitoring their societal impacts, such as disinformation, job displacement, and cultural homogenisation. Deckard calls for the embedding of ethical reflection throughout the AI lifecycle, arguing that computing professionals must be trained to identify and mitigate harm at every stage of system development.

Similarly, Floridi and Cowls (2019) propose a unified ethical framework that maps AI governance onto five principles: beneficence, non-maleficence, autonomy, justice, and explicability. These are not merely theoretical; they serve as a guide for reconciling the tensions between competing stakeholder priorities. For example, autonomy and explicability can help ensure that users understand and control how generative models make decisions—particularly in high-stakes domains such as healthcare and criminal justice.

A notable effort to articulate ethical AI principles with global reach is UNESCO’s *Recommendation on the Ethics of Artificial Intelligence* (2021). Unlike many regional frameworks, UNESCO’s guidelines are the result of consensus among 193 Member States. They promote human rights, sustainable development, and environmental stewardship, and call for an intersectional lens to AI governance that considers gender, ethnicity, disability, and socio-economic status. Crucially, the recommendation recognises data governance and algorithmic bias as structural challenges, not just technical ones—pushing for stronger institutions and public participation in AI policymaking.

Despite such efforts, most frameworks remain non-binding. This is where the *IEEE Ethically Aligned Design* (2019) offers a practical advancement. It emphasises value-based engineering and proposes concrete methodologies for translating abstract ethics into system requirements. For example, it promotes the use of impact assessments and traceability protocols to ensure that AI systems respect user intent and mitigate harm. Such standards could help operationalise ethics in a way that both developers and regulators can adopt uniformly.

Taken together, these sources expose a troubling paradox: while the global AI community broadly agrees on the ethical principles that should guide development, there is little agreement on how to implement them or who is accountable. To address this gap, I propose four interlinked recommendations:

1. **Institutional Coordination**  
   There is an urgent need for an international AI governance body, akin to the International Atomic Energy Agency (IAEA), to oversee transboundary issues and mediate ethical disputes. This would provide a forum for harmonising standards, supporting developing nations, and sharing best practices.

2. **Enforceable Auditing and Compliance**  
   Ethics must move beyond mission statements and into practice. Auditable metrics—such as fairness benchmarks, bias detection tools, and data provenance logs—should become regulatory requirements, not optional features. These mechanisms would support legal compliance and enable public accountability.

3. **Inclusion of Marginalised Voices**  
   Policymaking must centre the perspectives of those most at risk of harm from AI systems. This includes people with disabilities, racial and ethnic minorities, low-income communities, and the Global South. Co-creation, not mere consultation, must define future ethical frameworks.

4. **Professional Certification and Ethical Training**  
   Computing professionals should be held to ethical codes comparable to those in medicine or law. This includes not only technical competence but ongoing ethical education. Institutions like the ACM, IEEE, and BCS must continue to develop certification pathways that reflect evolving AI risks.

The legal, social, and professional implications of these actions are profound. Legally, enforceable ethics would strengthen regulatory clarity and improve compliance with privacy laws such as the GDPR or future AI-specific regulations. Socially, inclusive governance would reduce algorithmic discrimination, promote equitable access to AI benefits, and build public trust. Professionally, these changes would enhance the role of the computer scientist as a steward of social values, not just a technical executor.

In conclusion, the ethical challenges posed by generative AI are not merely theoretical—they are immediate, global, and systemic. As Correa et al. (2023) and Deckard (2023) show, ethical convergence without implementation is insufficient. AI governance must be built on foundations that are inclusive, enforceable, and globally coherent. By embedding ethical responsibility into our institutions, technical systems, and professional cultures, we can help shape a future where generative AI serves humanity rather than undermines it.

---

## Reference List 

Correa, D., Eisfeld, T., da Silva, G.C., Milani, P., & Martin, A. (2023) *Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance*. [Online]. Available at: https://arxiv.org/abs/2304.08696 [Accessed 4 May 2025].

Deckard, M. (2023) *What are ethics in AI?* [Online]. British Computer Society. Available at: https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/ [Accessed 4 May 2025].

Floridi, L. & Cowls, J. (2019) ‘A unified framework of five principles for AI in society’, *Harvard Data Science Review*, 1(1). doi: 10.1162/99608f92.8cd550d1.

Jobin, A., Ienca, M. & Vayena, E. (2019) ‘The global landscape of AI ethics guidelines’, *Nature Machine Intelligence*, 1(9), pp. 389–399. doi: 10.1038/s42256-019-0088-2.

IEEE (2019) *Ethically aligned design: A vision for prioritizing human well-being with autonomous and intelligent systems*, 1st ed. [Online]. IEEE. Available at: https://ethicsinaction.ieee.org/ [Accessed 3 May 2025].

UNESCO (2021) *Recommendation on the Ethics of Artificial Intelligence*. [Online]. Available at: https://unesdoc.unesco.org/ark:/48223/pf0000381137 [Accessed 3 May 2025].
